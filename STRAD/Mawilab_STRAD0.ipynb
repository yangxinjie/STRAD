{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from BaseOneClass import CentroidBasedOneClassClassifier,Centroid_Classifier\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder, MaxAbsScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kitsune import *\n",
    "import numpy as np\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import preprocess as p\n",
    "import trainer as t\n",
    "import time\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch import nn,optim\n",
    "#import pyhash \n",
    "import gensim\n",
    "import multiprocessing as mp\n",
    "from joblib import Parallel, delayed\n",
    "import concurrent.futures\n",
    "from pprint import pprint\n",
    "import random\n",
    "import mpld3 as mp\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import cluster\n",
    "from sklearn import manifold\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "import csv\n",
    "import time\n",
    "import joblib\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import sklearn as sk\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from gensim.models.doc2vec import Doc2Vec,TaggedDocument\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "import torch as th\n",
    "from torch.autograd import Variable as V\n",
    "from torch import nn,optim\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "from model import Skipgram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mawilab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frame.time_epoch</th>\n",
       "      <th>frame.len</th>\n",
       "      <th>eth.src</th>\n",
       "      <th>eth.dst</th>\n",
       "      <th>ip.src</th>\n",
       "      <th>ip.dst</th>\n",
       "      <th>tcp.srcport</th>\n",
       "      <th>tcp.dstport</th>\n",
       "      <th>udp.srcport</th>\n",
       "      <th>udp.dstport</th>\n",
       "      <th>...</th>\n",
       "      <th>arp.src.hw_mac</th>\n",
       "      <th>arp.src.proto_ipv4</th>\n",
       "      <th>arp.dst.hw_mac</th>\n",
       "      <th>arp.dst.proto_ipv4</th>\n",
       "      <th>ipv6.src</th>\n",
       "      <th>ipv6.dst</th>\n",
       "      <th>label</th>\n",
       "      <th>Proto</th>\n",
       "      <th>srcports</th>\n",
       "      <th>dstports</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.522559e+09</td>\n",
       "      <td>66</td>\n",
       "      <td>64:f6:9d:19:6a:52</td>\n",
       "      <td>88:e0:f3:7a:66:f0</td>\n",
       "      <td>61.146.199.121</td>\n",
       "      <td>163.157.17.9</td>\n",
       "      <td>65088.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>IPV4</td>\n",
       "      <td>65088.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.522559e+09</td>\n",
       "      <td>54</td>\n",
       "      <td>64:f6:9d:19:6a:52</td>\n",
       "      <td>88:e0:f3:7a:66:f0</td>\n",
       "      <td>181.84.22.161</td>\n",
       "      <td>163.157.101.85</td>\n",
       "      <td>46093.0</td>\n",
       "      <td>3341.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>IPV4</td>\n",
       "      <td>46093.0</td>\n",
       "      <td>3341.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.522559e+09</td>\n",
       "      <td>58</td>\n",
       "      <td>64:f6:9d:19:6a:52</td>\n",
       "      <td>88:e0:f3:7a:66:f0</td>\n",
       "      <td>202.126.140.214</td>\n",
       "      <td>203.205.168.38</td>\n",
       "      <td>25111.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>IPV4</td>\n",
       "      <td>25111.0</td>\n",
       "      <td>2000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.522559e+09</td>\n",
       "      <td>54</td>\n",
       "      <td>64:f6:9d:19:6a:52</td>\n",
       "      <td>88:e0:f3:7a:66:f0</td>\n",
       "      <td>218.217.229.57</td>\n",
       "      <td>133.138.78.17</td>\n",
       "      <td>32480.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>IPV4</td>\n",
       "      <td>32480.0</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.522559e+09</td>\n",
       "      <td>60</td>\n",
       "      <td>88:e0:f3:7a:66:f0</td>\n",
       "      <td>64:f6:9d:19:6a:52</td>\n",
       "      <td>203.205.139.208</td>\n",
       "      <td>179.128.197.118</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>icmp</td>\n",
       "      <td>icmp</td>\n",
       "      <td>icmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599995</th>\n",
       "      <td>1.522645e+09</td>\n",
       "      <td>1468</td>\n",
       "      <td>88:e0:f3:7a:66:f0</td>\n",
       "      <td>64:f6:9d:19:6a:52</td>\n",
       "      <td>203.50.132.47</td>\n",
       "      <td>124.246.145.151</td>\n",
       "      <td>80.0</td>\n",
       "      <td>50933.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>IPV4</td>\n",
       "      <td>80.0</td>\n",
       "      <td>50933.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599996</th>\n",
       "      <td>1.522645e+09</td>\n",
       "      <td>60</td>\n",
       "      <td>88:e0:f3:7a:66:f0</td>\n",
       "      <td>64:f6:9d:19:6a:52</td>\n",
       "      <td>203.50.155.157</td>\n",
       "      <td>188.122.181.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>icmp</td>\n",
       "      <td>icmp</td>\n",
       "      <td>icmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599997</th>\n",
       "      <td>1.522645e+09</td>\n",
       "      <td>1358</td>\n",
       "      <td>64:f6:9d:19:6a:52</td>\n",
       "      <td>88:e0:f3:7a:66:f0</td>\n",
       "      <td>204.62.82.225</td>\n",
       "      <td>203.50.137.79</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>IPV4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599998</th>\n",
       "      <td>1.522645e+09</td>\n",
       "      <td>66</td>\n",
       "      <td>64:f6:9d:19:6a:52</td>\n",
       "      <td>88:e0:f3:7a:66:f0</td>\n",
       "      <td>1.75.174.81</td>\n",
       "      <td>202.56.208.59</td>\n",
       "      <td>21657.0</td>\n",
       "      <td>443.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>IPV4</td>\n",
       "      <td>21657.0</td>\n",
       "      <td>443.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599999</th>\n",
       "      <td>1.522645e+09</td>\n",
       "      <td>60</td>\n",
       "      <td>88:e0:f3:7a:66:f0</td>\n",
       "      <td>64:f6:9d:19:6a:52</td>\n",
       "      <td>203.50.155.157</td>\n",
       "      <td>41.170.55.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>icmp</td>\n",
       "      <td>icmp</td>\n",
       "      <td>icmp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600000 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        frame.time_epoch  frame.len            eth.src            eth.dst  \\\n",
       "0           1.522559e+09         66  64:f6:9d:19:6a:52  88:e0:f3:7a:66:f0   \n",
       "1           1.522559e+09         54  64:f6:9d:19:6a:52  88:e0:f3:7a:66:f0   \n",
       "2           1.522559e+09         58  64:f6:9d:19:6a:52  88:e0:f3:7a:66:f0   \n",
       "3           1.522559e+09         54  64:f6:9d:19:6a:52  88:e0:f3:7a:66:f0   \n",
       "4           1.522559e+09         60  88:e0:f3:7a:66:f0  64:f6:9d:19:6a:52   \n",
       "...                  ...        ...                ...                ...   \n",
       "599995      1.522645e+09       1468  88:e0:f3:7a:66:f0  64:f6:9d:19:6a:52   \n",
       "599996      1.522645e+09         60  88:e0:f3:7a:66:f0  64:f6:9d:19:6a:52   \n",
       "599997      1.522645e+09       1358  64:f6:9d:19:6a:52  88:e0:f3:7a:66:f0   \n",
       "599998      1.522645e+09         66  64:f6:9d:19:6a:52  88:e0:f3:7a:66:f0   \n",
       "599999      1.522645e+09         60  88:e0:f3:7a:66:f0  64:f6:9d:19:6a:52   \n",
       "\n",
       "                 ip.src           ip.dst  tcp.srcport  tcp.dstport  \\\n",
       "0        61.146.199.121     163.157.17.9      65088.0         22.0   \n",
       "1         181.84.22.161   163.157.101.85      46093.0       3341.0   \n",
       "2       202.126.140.214   203.205.168.38      25111.0       2000.0   \n",
       "3        218.217.229.57    133.138.78.17      32480.0         23.0   \n",
       "4       203.205.139.208  179.128.197.118          NaN          NaN   \n",
       "...                 ...              ...          ...          ...   \n",
       "599995    203.50.132.47  124.246.145.151         80.0      50933.0   \n",
       "599996   203.50.155.157   188.122.181.25          NaN          NaN   \n",
       "599997    204.62.82.225    203.50.137.79          NaN          NaN   \n",
       "599998      1.75.174.81    202.56.208.59      21657.0        443.0   \n",
       "599999   203.50.155.157     41.170.55.50          NaN          NaN   \n",
       "\n",
       "        udp.srcport  udp.dstport  ...  arp.src.hw_mac  arp.src.proto_ipv4  \\\n",
       "0               NaN          NaN  ...             NaN                 NaN   \n",
       "1               NaN          NaN  ...             NaN                 NaN   \n",
       "2               NaN          NaN  ...             NaN                 NaN   \n",
       "3               NaN          NaN  ...             NaN                 NaN   \n",
       "4               NaN          NaN  ...             NaN                 NaN   \n",
       "...             ...          ...  ...             ...                 ...   \n",
       "599995          NaN          NaN  ...             NaN                 NaN   \n",
       "599996          NaN          NaN  ...             NaN                 NaN   \n",
       "599997          NaN          NaN  ...             NaN                 NaN   \n",
       "599998          NaN          NaN  ...             NaN                 NaN   \n",
       "599999          NaN          NaN  ...             NaN                 NaN   \n",
       "\n",
       "        arp.dst.hw_mac  arp.dst.proto_ipv4  ipv6.src  ipv6.dst  label Proto  \\\n",
       "0                  NaN                 NaN       NaN       NaN      0  IPV4   \n",
       "1                  NaN                 NaN       NaN       NaN      1  IPV4   \n",
       "2                  NaN                 NaN       NaN       NaN      0  IPV4   \n",
       "3                  NaN                 NaN       NaN       NaN      0  IPV4   \n",
       "4                  NaN                 NaN       NaN       NaN      0  icmp   \n",
       "...                ...                 ...       ...       ...    ...   ...   \n",
       "599995             NaN                 NaN       NaN       NaN      1  IPV4   \n",
       "599996             NaN                 NaN       NaN       NaN      1  icmp   \n",
       "599997             NaN                 NaN       NaN       NaN      0  IPV4   \n",
       "599998             NaN                 NaN       NaN       NaN      0  IPV4   \n",
       "599999             NaN                 NaN       NaN       NaN      1  icmp   \n",
       "\n",
       "       srcports  dstports  \n",
       "0       65088.0      22.0  \n",
       "1       46093.0    3341.0  \n",
       "2       25111.0    2000.0  \n",
       "3       32480.0      23.0  \n",
       "4          icmp      icmp  \n",
       "...         ...       ...  \n",
       "599995     80.0   50933.0  \n",
       "599996     icmp      icmp  \n",
       "599997      NaN       NaN  \n",
       "599998  21657.0     443.0  \n",
       "599999     icmp      icmp  \n",
       "\n",
       "[600000 rows x 23 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path ='maiwilab.tsv'\n",
    "#all_data.to_csv(path,sep='\\t',index=False)\n",
    "all_data=pd.read_csv(path,sep='\\t')\n",
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data=all_data[:300000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    63820\n",
       "1    23680\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data[:87500]['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "num_steps = 500\n",
    "batch_size = 100\n",
    "display_step = 10\n",
    "# Network Parameters\n",
    "num_hidden_1 = 85 # 1st layer num features\n",
    "num_hidden_2 = 49 # 2nd layer num features (the latent dim)\n",
    "num_hidden_3 = 12 # 3nd layer num features (the latent dim)\n",
    "select_feature=['ip.src','ip.dst','dstports','Proto']\n",
    "train_num=75000\n",
    "test_num=25000\n",
    "\n",
    "\n",
    "vec_emb_dim=10\n",
    "vec_max_epoch=1\n",
    "vec_batch_size=5\n",
    "vec_neg_num=10\n",
    "\n",
    "#\"../data/maiwilab300000.tsv\"\n",
    "packet_limit = np.Inf #the number of packets to process\n",
    "\n",
    "# KitNET params:\n",
    "maxAE = 10 #maximum size for any autoencoder in the ensemble layer\n",
    "FMgrace = 40000 #the number of instances taken to learn the feature mapping (the ensemble's architecture)\n",
    "ADgrace = train_num #the number of instances used to train the anomaly detector (ensemble itself)\n",
    "alpha=10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-7a124a4af202>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_data['label']=label\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal training data:  55434\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8ed61a4cc774a98834965ceb6d54181",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=300000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34a7a1dbe8c14ac28fd38b8af7728eef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=75000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34c376b03ab44911bf4d6b61c987f1c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=300000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d81f473034f4bf6b82207a4f720f575",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=75000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "start training feature\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66cb4a1c7538482a921455b038b99a7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=75000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0 0\n",
      "Complete. Time elapsed: 1916.3289942741394\n",
      "tsv\n",
      "counting lines in file...\n",
      "There are 600001 Packets.\n",
      "Feature-Mapper: train-mode, Anomaly-Detector: off-mode\n",
      "Running Kitsune:\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "Complete. Time elapsed: 1065.8488252162933\n",
      "Normal training data:  55434\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "label=all_data['label']\n",
    "all_data['label']=label\n",
    "train_data=all_data[:train_num]\n",
    "x_train = train_data[train_data['label']==0]        #Select only normal data for training  \n",
    "print(\"Normal training data: \", x_train.shape[0]) \n",
    "start = time.time()\n",
    "X =train_data\n",
    "X=X.loc[:,select_feature]\n",
    "d = X.to_numpy()\n",
    "w2v,v2w = p._w2v(d)\n",
    "corpus = pd.DataFrame(p._corpus(d, w2v)).to_numpy()\n",
    "freq  = p._frequency(d)\n",
    "train = np.array(p._data_loader(corpus, batch_size))\n",
    "print(\"start training feature\\n\")\n",
    "model = t.Trainer(w2v,v2w,freq,emb_dim=vec_emb_dim)\n",
    "model.fit(data = train,max_epoch=vec_max_epoch,batch_size=vec_batch_size,neg_num=vec_neg_num)\n",
    "\n",
    "\n",
    "W = model.model.state_dict()[\"u_embedding.weight\"]\n",
    "X3=[]\n",
    "for batch in corpus[:train_num]:\n",
    "    ok=[]\n",
    "    for index in batch:\n",
    "        ok.append(W[index].numpy().tolist())\n",
    "    X3.append(ok)\n",
    "        \n",
    "\n",
    "X4=np.array(X3).reshape(train_num, len(select_feature)*vec_emb_dim)   \n",
    "\n",
    "stop = time.time()\n",
    "print(\"Complete. Time elapsed: \"+ str(stop - start))\n",
    "K = Kitsune(path,packet_limit,maxAE,FMgrace,ADgrace)\n",
    "\n",
    "print(\"Running Kitsune:\")\n",
    "Xvectors = []\n",
    "i = 0\n",
    "start = time.time()\n",
    "# Here we process (train/execute) each individual packet.\n",
    "# In this way, each observation is discarded after performing process() method.\n",
    "while True:\n",
    "    i+=1\n",
    "    if i%10000==0 :\n",
    "        print(i)\n",
    "    if i ==train_num+1:\n",
    "        break\n",
    "    rmse = K.proc_next_packet()\n",
    "    Xvectors.append(rmse)\n",
    "stop = time.time()\n",
    "print(\"Complete. Time elapsed: \"+ str(stop - start))\n",
    "kitsune=Xvectors\n",
    "x=X4\n",
    "x=np.concatenate((x[:train_num],kitsune[:train_num]),axis=1)\n",
    "label=pd.read_csv(path,sep='\\t')['label']\n",
    "x=pd.DataFrame(x)\n",
    "x['label']=label[:train_num]\n",
    "train_data=x[:train_num].values\n",
    "y_train = train_data[:,-1]                #Select label column\n",
    "x_train = train_data[y_train == 0]        #Select only normal data for training  \n",
    "x_train = x_train[:,0:-1]                 #Remove label column\n",
    "print(\"Normal training data: \", x_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "20000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f8ac420411d461587e201ee77609184",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=400000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "578e641585664d49b71ce1944b4ca81a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=100000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "763b52f845d9476591c3c6dc5a68ab30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=400000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86090637fb624eb2993ed134a07eb558",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=100000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14e38c7c137e4af98dae9941e663e2df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=25000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0 0\n",
      "Normal testing data:  15765\n",
      "Anomaly testing data:  9235\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Xtest = []\n",
    "i = 0\n",
    "start = time.time()\n",
    "# Here we process (train/execute) each individual packet.\n",
    "# In this way, each observation is discarded after performing process() method.\n",
    "while True:\n",
    "    i+=1\n",
    "    if i%10000==0 :\n",
    "        \n",
    "        print(i)\n",
    "    if i ==test_num+1:\n",
    "        break\n",
    "    rmse = K.proc_next_packet()\n",
    "    Xtest.append(rmse)\n",
    "stop = time.time()\n",
    "modeltest = copy.deepcopy(model)\n",
    "dtest = all_data.loc[:,select_feature].to_numpy()[:train_num+test_num]\n",
    "w2vtest,v2wtest = p._w2v(dtest)\n",
    "corpustest = pd.DataFrame(p._corpus(dtest, w2vtest)).to_numpy()\n",
    "freqtest  = p._frequency(dtest)\n",
    "traintest = np.array(p._data_loader(corpustest, batch_size))\n",
    "#modeltest=model\n",
    "modeltest.w2v=w2vtest\n",
    "modeltest.v2w=v2wtest\n",
    "modeltest.unigram_table = modeltest.noise(modeltest.w2v,freqtest)\n",
    "modeltest.vocab_size = len(modeltest.w2v)\n",
    "modeltest.model.vocab_size=len(modeltest.w2v)\n",
    "a=model.model.u_embedding.weight\n",
    "b=th.zeros(modeltest.model.vocab_size-model.model.vocab_size,modeltest.model.emb_dim)\n",
    "modeltest.model.u_embedding.weight=th.nn.Parameter(th.cat((a, b), 0))\n",
    "modeltest.model.v_embedding.weight=th.nn.Parameter(th.cat((model.model.v_embedding.weight, b), 0))\n",
    "modeltest.fit(data = traintest[train_num:train_num+test_num],max_epoch=vec_max_epoch,batch_size=vec_batch_size,neg_num=vec_neg_num)\n",
    "W = modeltest.model.state_dict()[\"u_embedding.weight\"]\n",
    "X3=[]\n",
    "i=0\n",
    "for batch in corpustest[train_num:train_num+test_num]:\n",
    "    ok=[]\n",
    "    i+=1\n",
    "    for index in batch:\n",
    "        ok.append(W[index].numpy().tolist())\n",
    "    X3.append(ok)\n",
    "X4=np.array(X3).reshape(i, len(select_feature)*vec_emb_dim)\n",
    "x=np.concatenate((X4,Xtest),axis=1)\n",
    "test_data=x\n",
    "x_test = test_data\n",
    "y_test=all_data['label'][train_num:train_num+test_num]\n",
    "test_X0 = x_test[y_test == 0]             #Normal test\n",
    "test_X1 = x_test[y_test > 0]              #Anomaly test \n",
    "print(\"Normal testing data: \", test_X0.shape[0])\n",
    "print(\"Anomaly testing data: \", test_X1.shape[0])\n",
    "x_test = np.concatenate((test_X0, test_X1))\n",
    "test_y0 = np.full((len(test_X0)), True, dtype=bool)\n",
    "test_y1 = np.full((len(test_X1)), False,  dtype=bool)\n",
    "y_test =  np.concatenate((test_y0, test_y1))\n",
    "\n",
    "#create binary label (1-normal, 0-anomaly) for compute AUC later\n",
    "y_test = (y_test).astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((75000,), (75000, 64))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape,train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('train_data_TrueOnlyCEN',train_data[:,0:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('x_train_TrueOnlyCEN',x_train)\n",
    "np.save('y_train_TrueOnlyCEN',y_train)\n",
    "np.save('x_test_TrueOnlyCEN',x_test)\n",
    "np.save('y_test_TrueOnlyCEN',y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=np.load('x_train_TrueOnlyCEN.npy')\n",
    "y_train=np.load('y_train_TrueOnlyCEN.npy').astype(np.int)\n",
    "x_test=np.load('x_test_TrueOnlyCEN.npy')\n",
    "y_test=np.load('y_test_TrueOnlyCEN.npy').astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63\n"
     ]
    }
   ],
   "source": [
    "\n",
    "scaler = MaxAbsScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train = scaler.transform(x_train)\n",
    "x_test  = scaler.transform(x_test)\n",
    "\n",
    "\n",
    "n_input = x_train.shape[1]\n",
    "print(n_input)\n",
    "\n",
    "\n",
    "from tensorflow.python.framework import ops\n",
    "ops.reset_default_graph()\n",
    "#tf.reset_default_graph()\n",
    "# tf Graph input (only pictures)\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "X = tf.placeholder(\"float\", [None, n_input])\n",
    "#Function to compute The Area Under ROC Curve\n",
    "def AUC_AE(x_test, y_test):\n",
    "    recon_X      = sess.run(decoder_op, feed_dict={X:x_test})\n",
    "    recon_errors = ((recon_X - x_test)**2).mean(1)\n",
    "    \n",
    "    predictions = -recon_errors\n",
    "    FPR, TPR, thresholds = roc_curve(y_test, predictions)\n",
    "    auc_ae = auc(FPR, TPR)\n",
    "    return FPR, TPR, auc_ae\n",
    "\n",
    "#Function to compute The Area Under ROC Curve\n",
    "def AUC_SVM(z_train, z_test, y_test):\n",
    "    #- Trainning SVM using Z\n",
    "    clf = svm.OneClassSVM(nu=0.1, kernel=\"rbf\", gamma=0.1)\n",
    "    clf.fit(z_train)\n",
    "    z_pred_test = clf.decision_function(z_test)\n",
    "    \n",
    "    predictions = z_pred_test\n",
    "    FPR, TPR, thresholds = roc_curve(y_test, predictions)\n",
    "    auc_svm = auc(FPR, TPR)\n",
    "    return FPR, TPR, auc_svm\n",
    "\n",
    "def AUC_CEN(z_train, z_test, y_test):\n",
    "    CEN = CentroidBasedOneClassClassifier()\n",
    "    CEN.fit(z_train)  \n",
    "    z_pred_test = -CEN.get_density(z_test)\n",
    "    \n",
    "    FPR, TPR, thresholds = roc_curve(y_test, z_pred_test)\n",
    "    auc_cen = auc(FPR, TPR) \n",
    "    return FPR, TPR, auc_cen\n",
    "def normalize_data(data):\n",
    "    MaxAbs_data = tf.reduce_max(tf.abs(data), axis =0)\n",
    "    #m = sess.run(MaxAbs_data)\n",
    "    data_norm =   data/MaxAbs_data\n",
    "    return data_norm\n",
    "def xavier_init(size):\n",
    "    in_dim = size[0]\n",
    "    xavier_stddev = 1. / tf.sqrt(in_dim / 2.)\n",
    "    return tf.random_normal(shape=size, stddev=xavier_stddev)\n",
    "weights_en = {\n",
    "    'encoder_h1': tf.Variable(xavier_init([n_input, num_hidden_1])),\n",
    "    'encoder_h2': tf.Variable(xavier_init([num_hidden_1, num_hidden_2])),\n",
    "    'encoder_h3': tf.Variable(xavier_init([num_hidden_2, num_hidden_3]))\n",
    "}\n",
    "\n",
    "weights_de = {\n",
    "    'decoder_h1': tf.transpose(weights_en['encoder_h3']),    #12-49\n",
    "    'decoder_h2': tf.transpose(weights_en['encoder_h2']),    #49 - 85\n",
    "    'decoder_h3': tf.transpose(weights_en['encoder_h1']),    #85 - 122 \n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'encoder_b1': tf.Variable(tf.zeros(shape=[num_hidden_1])),\n",
    "    'encoder_b2': tf.Variable(tf.zeros(shape=[num_hidden_2])),  \n",
    "    'encoder_b3': tf.Variable(tf.zeros(shape=[num_hidden_3])), \n",
    "    \n",
    "    'decoder_b1': tf.Variable(tf.zeros(shape=[num_hidden_2])), \n",
    "    'decoder_b2': tf.Variable(tf.zeros(shape=[num_hidden_1])),\n",
    "    'decoder_b3': tf.Variable(tf.zeros(shape=[n_input]))\n",
    "}\n",
    "def encoder(x):\n",
    "    # Encoder Hidden layer with sigmoid activation\n",
    "    layer_1 = tf.nn.tanh(tf.add(tf.matmul(x, weights_en['encoder_h1']), biases['encoder_b1']))\n",
    "    \n",
    "    # Encoder Hidden layer with sigmoid activation\n",
    "    layer_2 = tf.nn.tanh(tf.add(tf.matmul(layer_1, weights_en['encoder_h2']), biases['encoder_b2']))\n",
    "\n",
    "    # Encoder Hidden layer with sigmoid activation\n",
    "    layer_3 = tf.nn.tanh(tf.add(tf.matmul(layer_2, weights_en['encoder_h3']), biases['encoder_b3']))\n",
    "    \n",
    "    return layer_3\n",
    "\n",
    "\n",
    "\n",
    "def decoder(x):\n",
    "    # Decoder Hidden layer with sigmoid activation \n",
    "    layer_1 = tf.nn.tanh(tf.add(tf.matmul(x, weights_de['decoder_h1']), biases['decoder_b1']))\n",
    "    \n",
    "    # Decoder Hidden layer with sigmoid activation\n",
    "    layer_2 = tf.nn.tanh(tf.add(tf.matmul(layer_1, weights_de['decoder_h2']), biases['decoder_b2']))\n",
    "\n",
    "    layer_3 = tf.nn.tanh(tf.add(tf.matmul(layer_2, weights_de['decoder_h3']), biases['decoder_b3']))\n",
    "    \n",
    "    return layer_3\n",
    "\n",
    "\n",
    "# Construct model\n",
    "encoder_op = encoder(X)\n",
    "decoder_op = decoder(encoder_op)\n",
    "\n",
    "# Prediction\n",
    "y_pred = decoder_op\n",
    "x_encoder=encoder_op\n",
    "# Targets (Labels) are the input data.\n",
    "y_true = X\n",
    "\n",
    "#x_encoder1 = normalize_data(x_encoder)\n",
    "\n",
    "# Define loss and optimizer, minimize the squared error\n",
    "loss = tf.reduce_mean(tf.pow(y_true - y_pred, 2))+ alpha*tf.reduce_mean(tf.pow(x_encoder,2))\n",
    "#loss = tf.reduce_mean(tf.pow(y_true - y_pred, 2))+ tf.reduce_mean(tf.pow(x_encoder1,2))\n",
    "\n",
    "#optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "optimizer = tf.train.AdadeltaOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step   0: Minibatch Loss: 2.3094 - AUC_AE 0.435 - AUC_SVM:0.856 - AUC_CEN:0.920\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "\n",
    "# Run the initializer\n",
    "sess.run(init)\n",
    "\n",
    "num_batch = int(x_train.shape[0]/batch_size)\n",
    "# Training\n",
    "train_history=[]\n",
    "for i in range(num_steps):\n",
    "    # Prepare Data\n",
    "    re = 0\n",
    "    for i_batch in range(num_batch):\n",
    "        batch_x = x_train[i_batch*batch_size:(i_batch+1)*batch_size] \n",
    "        _, re_batch = sess.run([optimizer, loss], feed_dict={X: batch_x})\n",
    "        re = re + re_batch\n",
    "        # Display logs per step\n",
    "    if i % display_step == 0 or i == 1:\n",
    "        z_train = sess.run(x_encoder,feed_dict={X:x_train})\n",
    "        z_test = sess.run(x_encoder,feed_dict={X:x_test})\n",
    "        #print(type(x_test),type(y_test))\n",
    "        _,_,auc_ae    = AUC_AE(x_test, y_test)\n",
    "        _,_,auc_svm = AUC_SVM(z_train, z_test, y_test)\n",
    "        _,_,auc_cen = AUC_CEN(z_train, z_test, y_test)\n",
    "        if len(train_history)>0 and auc_cen<train_history[-1][2]:\n",
    "            break\n",
    "        train_history.append([auc_ae,auc_svm,auc_cen])\n",
    "        print('Step %3.0i: Minibatch Loss: %0.4f - AUC_AE %0.3f - AUC_SVM:%0.3f - AUC_CEN:%0.3f' % (i, re/num_batch, auc_ae, auc_svm, auc_cen ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9200679161496768"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "CEN = CentroidBasedOneClassClassifier()\n",
    "CEN.fit(z_train)  \n",
    "z_pred_test = -CEN.get_density(z_test)\n",
    "FPR, TPR, thresholds = roc_curve(y_test, z_pred_test)\n",
    "cen = auc(FPR, TPR) \n",
    "RightIndex=(TPR+(1-FPR)-1)\n",
    "index=np.argmax(RightIndex)\n",
    "tpr_val=TPR[index]\n",
    "fpr_val=FPR[index]\n",
    "thresholds_val=thresholds[index]\n",
    "y_pred=[0 if i<thresholds_val else 1 for i in z_pred_test]\n",
    "sk.metrics.f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision 0.948051948051948\n",
      "Recall 0.8936885505867428\n",
      "f1_score 0.9200679161496768\n"
     ]
    }
   ],
   "source": [
    "pre=sk.metrics.precision_score(y_test, y_pred)\n",
    "rec=sk.metrics.recall_score(y_test, y_pred)\n",
    "f1= sk.metrics.f1_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "print(\"Precision\", pre)\n",
    "print( \"Recall\",rec)\n",
    "print( \"f1_score\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
