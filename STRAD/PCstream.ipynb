{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Use this function when you have a pcS model collection, and which to classify a new observation (i.e. label it's cluster by index)\n",
    "def classifyOb(x, modelCollection):\n",
    "\t#x is a single 1-by-n observation. modelCollection is a list of pcS models in the form: (X,A,mu) -see paper\n",
    "\t#score observation\n",
    "\tscores = np.zeros(len(modelCollection))\n",
    "\tfor i in range(0,len(scores)):\n",
    "\t\t#transform the observation to the new basis\n",
    "\t\txtag = (x - modelCollection[i][2])\n",
    "\t\ttransPoint = np.dot(xtag,modelCollection[i][1])\n",
    "\t\tscores[i] = np.dot(transPoint,transPoint.T)\n",
    "\tscores = np.sqrt(scores)\n",
    "\t\n",
    "\t#Find most likely model\n",
    "\tbestScore = min(scores)\n",
    "\treturn np.where(scores==bestScore)[0][0]\n",
    "\n",
    "def modelCluster(X, pVar):\n",
    "\t#perform pca on X\n",
    "\tX = np.array(X)\n",
    "\tmu = np.mean(X.T,axis=1)\n",
    "\tM = (X-mu).T # subtract the mean (along columns)\n",
    "\t[latent,coeff] = np.linalg.eig(np.cov(M)) # attention:not always sorted\n",
    "\torder = [i[0] for i in sorted(enumerate(np.absolute(latent)), key=lambda x:x[1],reverse=True)]\n",
    "\tlatent = latent[order]\n",
    "\tcoeff = coeff[:,order]\t\n",
    "\tcontributions = latent/sum(latent)\n",
    "\t\n",
    "\t#only retain the PCs that contain the Pvar percent of variance of the data.\n",
    "\tif pVar == 1:\n",
    "\t\tnumPCs = len(latent)\n",
    "\telse:\n",
    "\t\tnumPCs = next((i for i, v in enumerate(np.cumsum(contributions)) if v >= pVar),len(latent)-1)+1\n",
    "\t\n",
    "\tLtag = latent[0:numPCs]\n",
    "\tD = np.sqrt(Ltag); \n",
    "\tC = coeff[:,0:numPCs]\n",
    "\tA = np.dot(C,np.diag(D))\n",
    "\treturn (X,A,mu)\n",
    "\n",
    "\n",
    "def pcS(X, pcS_args): #dataset is an ordered rdd with each row being an observation \n",
    "  #pcS_args: (DriftThreshold, DriftSize -must be greater than n, PercentVareince, ModelMemorySize -greater then driftSize)\n",
    "\tif isinstance(X,list):\n",
    "\t\tX = np.array(X)\n",
    "\tn = X.shape[1] #the number of features\n",
    "\tm = X.shape[0]\n",
    "\t\n",
    "\tdriftThr = pcS_args[0] #Drift Threshold -set to 1/4th the dataset's std\n",
    "\tdriftSize = pcS_args[1] #Buffer size: max drift size -set to 10 times the number of features\n",
    "\tpVar = pcS_args[2] #Percent variance to retain\n",
    "\tmodelMemSize = pcS_args[3] #the memory size of each model - 10times the drift size\n",
    "\t\n",
    "\tmodelCollection = list()\n",
    "\tmodelCollection.append(modelCluster(X[0:driftSize,:],pVar)) #initial model\n",
    "\t\n",
    "\tlabels = [0]*driftSize\n",
    "\tdriftBuffer = list()\n",
    "\tcurModel = 0\n",
    "\t\n",
    "\t#Begin reading stream\n",
    "\tprint \"beginning stream\"\n",
    "\tfor x in X[driftSize+1:,:]: #continue pcStream\n",
    "\t\t# process next observation\n",
    "\t\t#score observation\n",
    "\t\tscores = np.zeros(len(modelCollection))\n",
    "\t\tfor i in range(0,len(scores)):\n",
    "\t\t\t#transform the observation to the new basis\n",
    "\t\t\txtag = (x - modelCollection[i][2])\n",
    "\t\t\ttransPoint = np.dot(xtag,modelCollection[i][1])\n",
    "\t\t\tscores[i] = np.dot(transPoint,transPoint.T)\n",
    "\t\tscores = np.sqrt(scores)\n",
    "\t\t#Find most likely model\n",
    "\t\tbestScore = min(scores)\n",
    "\t\tbestModl = np.where(scores==bestScore)[0][0]\n",
    "\t\tdel scores\n",
    "\t\t\n",
    "\t\t#Detect drift\n",
    "\t\tif bestScore > driftThr:\n",
    "\t\t\t# Add the drifter to a buffer\n",
    "\t\t\tdriftBuffer.append(x)\n",
    "\t\t\t\n",
    "\t\t\t#Check if the buffer is full (has enough to make a substantial model\n",
    "\t\t\tif len(driftBuffer) == driftSize:\n",
    "\t\t\t\tmodelCollection.append(modelCluster(driftBuffer,pVar))\n",
    "\t\t\t\tcurModel = len(modelCollection)-1\n",
    "\t\t\t\tlabels = labels + [curModel]*len(driftBuffer)\n",
    "\t\t\t\tdel driftBuffer[:]\n",
    "\t\t\t\t\n",
    "\t\t\n",
    "\t\telse: # there was no drift\n",
    "\t\t\t#Check for partial drift\n",
    "\t\t\tif len(driftBuffer) > 0:\n",
    "\t\t\t\tx = [x] + driftBuffer\n",
    "\t\t\t\tlabels = labels + [bestModl]*len(driftBuffer)\n",
    "\t\t\t\tdel driftBuffer[:]\n",
    "\t\t\t\n",
    "\t\t\t# assign current observation\n",
    "\t\t\tcurModel = bestModl\n",
    "\t\t\tif isinstance(x,np.ndarray):\n",
    "\t\t\t\tx = [x]\n",
    "\t\t\t\n",
    "\t\t\tmodelCollection[curModel] = modelCluster( (x+list(modelCollection[curModel][0]))[0:modelMemSize], pVar)\n",
    "\t\t\tlabels.append(curModel)\n",
    "\t\t\t#time.sleep(1) #for debugging...   \t\t\t\t\t\n",
    "\t# empty dirftBuffer one last time\n",
    "\tmodelCollection[curModel] = modelCluster( (driftBuffer + list(modelCollection[curModel][0]))[0:modelMemSize], pVar)\n",
    "\tlabels = labels + [curModel]*len(driftBuffer)\n",
    "\t\n",
    "\t# End of pcStream:\n",
    "\treturn (modelCollection, labels)\n",
    "\n",
    "\n",
    "def genDataset(conceptDurations,conceptScale,ConceptOffsetScale,numConcepts,numFeatures):\n",
    "\tconceptScale = float(conceptScale)\n",
    "\tConceptOffsetScale = float(ConceptOffsetScale)\t\t\n",
    "\tcurConcept = 0\n",
    "\twhile curConcept < numConcepts:\n",
    "\t\tcurConcept += 1\n",
    "\t\tcurObs = 0 # there are \"conceptDurations\" of observation in each concept\n",
    "\t\twhile curObs < conceptDurations:\n",
    "\t\t\tcurObs += 1\n",
    "\t\t\tyield (np.random.randn(1,numFeatures)*(np.random.rand(1,numFeatures)*conceptScale)-np.random.rand(1,numFeatures)*ConceptOffsetScale)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "X_train=np.load('x_train_mawilab.npy')\n",
    "X_test=np.load('x_test_mawilab.npy')\n",
    "y_train=np.load('y_train_mawilab.npy')#pd.read_csv('../data/maiwilab300000.tsv',sep='\\t')['label']\n",
    "y_test=np.load('y_test_mawilab.npy')\n",
    "x=np.concatenate((X_train,X_test),axis=0)\n",
    "y=np.concatenate((y_train,y_test),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=pd.DataFrame(x)\n",
    "cols_to_norm = [ i for i in range(0,63) ]\n",
    "\n",
    "x.loc[:, cols_to_norm] = (x[cols_to_norm] - x[cols_to_norm].mean()) / x[cols_to_norm].std()\n",
    "x=x.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beginning stream\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/lr27/lib/python2.7/site-packages/ipykernel_launcher.py:72: ComplexWarning: Casting complex values to real discards the imaginary part\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============  Done.  ============\n",
      "It took 8.45229101181 seconds to train pcStream over a stream of 12500  63-dimensional observations.\n",
      "   Number of clusters found: 5\n",
      "   The clusters have the following number of assigned observations:  \n",
      "       Cluster 0: 10000\n",
      "       Cluster 1: 1399\n",
      "       Cluster 2: 305\n",
      "       Cluster 3: 147\n",
      "       Cluster 4: 94\n",
      "  \n",
      "Predicting (scoring) new observation x:\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import timeit\n",
    "\n",
    "# If you use the source code or impliment pcStream, please cite the following paper:\n",
    "# Mirsky, Yisroel, Bracha Shapira, Lior Rokach, and Yuval Elovici. \"pcStream: A Stream Clustering Algorithm for Dynamically Detecting and Managing Temporal Contexts.\" In Advances in Knowledge Discovery and Data Mining (PAKDD), pp. 119-133. Springer International Publishing, 2015.\n",
    "\n",
    "#### Demo ####\n",
    "\n",
    "# generate a test dataset\n",
    "conceptDuration = 1000\n",
    "conceptDistributionScale = 1\n",
    "conceptOffset = 3\n",
    "numSequentialConcepts = 10\n",
    "n = 63 #number of features\n",
    "\n",
    "# DataGen = genDataset(conceptDuration,conceptDistributionScale,conceptOffset,numSequentialConcepts,n) #pcStream.genDataset is a python generator for testing purposes. It generates random sequential overalping normal distributions\n",
    "# Dataset = list()\n",
    "\n",
    "# for x in DataGen:\n",
    "#     Dataset.append(x)\n",
    "Dataset=x[87500:]\n",
    "m = len(Dataset) #length of stream\n",
    "\n",
    "# Run pcStream\n",
    "driftThreshold = 8.7 # note, it is generally reccoemnded to zscore the dataset before hand. In which case, the driftThreshold is typically slightly above 1\n",
    "maxDriftSize = int(n*1.5)\n",
    "percentVarience = 0.60\n",
    "modelMemory = 10000\n",
    "\n",
    "pcS_args = (driftThreshold,maxDriftSize,percentVarience,modelMemory) #pcStream argumetns are passed to the function as a tuple\n",
    "start = timeit.default_timer()\t\n",
    "Result =pcS(Dataset,pcS_args) #Result is the tuple (pcStreamModelCollection, clusterLabels)\n",
    "stop = timeit.default_timer()\n",
    "modelCollection  = Result[0]\n",
    "\n",
    "print \"============  Done.  ============\"\n",
    "print \"It took \" + str(stop-start) + \" seconds to train pcStream over a stream of \" + str(m) + \"  \" + str(n) + \"-dimensional observations.\"\n",
    "print \"   Number of clusters found: \" + str(len(modelCollection))\n",
    "print \"   The clusters have the following number of assigned observations:  \"\n",
    "for cluster in range(0,len(modelCollection)): #a pcStream cluster has the form (X,A,mu) -see the paper\n",
    "    print \"       Cluster \" + str(cluster) + \": \" + str(len(modelCollection[cluster][0]))\n",
    "\n",
    "print \"  \"\n",
    "print \"Predicting (scoring) new observation x:\"\n",
    "#x =genDataset(conceptDuration,conceptDistributionScale,conceptOffset,numSequentialConcepts,n).next() # some random observation...\n",
    "y_pred=[]\n",
    "for i in x[87500:]:\n",
    "    y_pred.append(classifyOb(i, modelCollection))\n",
    "import collections\n",
    "count2=collections.Counter(y_pred )\n",
    "count3=collections.Counter(y[87500:] )\n",
    "print(count2,count3)\n",
    "y_pred2=[]\n",
    "for i in y_pred:\n",
    "    if i==2:\n",
    "        y_pred2.append(1)\n",
    "    else:\n",
    "        y_pred2.append(0)\n",
    "count2=collections.Counter(y_pred2)\n",
    "print(count2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beginning stream\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/lr27/lib/python2.7/site-packages/ipykernel_launcher.py:72: ComplexWarning: Casting complex values to real discards the imaginary part\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============  Done.  ============\n",
      "It took 61.7211670876 seconds to train pcStream over a stream of 87500  63-dimensional observations.\n",
      "   Number of clusters found: 357\n",
      "   The clusters have the following number of assigned observations:  \n",
      "       Cluster 0: 94\n",
      "       Cluster 1: 349\n",
      "       Cluster 2: 118\n",
      "       Cluster 3: 192\n",
      "       Cluster 4: 130\n",
      "       Cluster 5: 115\n",
      "       Cluster 6: 422\n",
      "       Cluster 7: 216\n",
      "       Cluster 8: 157\n",
      "       Cluster 9: 94\n",
      "       Cluster 10: 94\n",
      "       Cluster 11: 143\n",
      "       Cluster 12: 412\n",
      "       Cluster 13: 141\n",
      "       Cluster 14: 359\n",
      "       Cluster 15: 94\n",
      "       Cluster 16: 174\n",
      "       Cluster 17: 276\n",
      "       Cluster 18: 94\n",
      "       Cluster 19: 127\n",
      "       Cluster 20: 94\n",
      "       Cluster 21: 94\n",
      "       Cluster 22: 142\n",
      "       Cluster 23: 222\n",
      "       Cluster 24: 614\n",
      "       Cluster 25: 171\n",
      "       Cluster 26: 417\n",
      "       Cluster 27: 94\n",
      "       Cluster 28: 133\n",
      "       Cluster 29: 166\n",
      "       Cluster 30: 181\n",
      "       Cluster 31: 94\n",
      "       Cluster 32: 168\n",
      "       Cluster 33: 151\n",
      "       Cluster 34: 118\n",
      "       Cluster 35: 126\n",
      "       Cluster 36: 521\n",
      "       Cluster 37: 201\n",
      "       Cluster 38: 972\n",
      "       Cluster 39: 262\n",
      "       Cluster 40: 94\n",
      "       Cluster 41: 1067\n",
      "       Cluster 42: 107\n",
      "       Cluster 43: 500\n",
      "       Cluster 44: 152\n",
      "       Cluster 45: 661\n",
      "       Cluster 46: 94\n",
      "       Cluster 47: 766\n",
      "       Cluster 48: 96\n",
      "       Cluster 49: 94\n",
      "       Cluster 50: 165\n",
      "       Cluster 51: 163\n",
      "       Cluster 52: 183\n",
      "       Cluster 53: 94\n",
      "       Cluster 54: 182\n",
      "       Cluster 55: 716\n",
      "       Cluster 56: 94\n",
      "       Cluster 57: 504\n",
      "       Cluster 58: 99\n",
      "       Cluster 59: 147\n",
      "       Cluster 60: 94\n",
      "       Cluster 61: 97\n",
      "       Cluster 62: 94\n",
      "       Cluster 63: 173\n",
      "       Cluster 64: 1229\n",
      "       Cluster 65: 297\n",
      "       Cluster 66: 94\n",
      "       Cluster 67: 231\n",
      "       Cluster 68: 179\n",
      "       Cluster 69: 94\n",
      "       Cluster 70: 278\n",
      "       Cluster 71: 345\n",
      "       Cluster 72: 94\n",
      "       Cluster 73: 245\n",
      "       Cluster 74: 2741\n",
      "       Cluster 75: 158\n",
      "       Cluster 76: 94\n",
      "       Cluster 77: 94\n",
      "       Cluster 78: 928\n",
      "       Cluster 79: 165\n",
      "       Cluster 80: 433\n",
      "       Cluster 81: 146\n",
      "       Cluster 82: 138\n",
      "       Cluster 83: 106\n",
      "       Cluster 84: 165\n",
      "       Cluster 85: 210\n",
      "       Cluster 86: 94\n",
      "       Cluster 87: 230\n",
      "       Cluster 88: 280\n",
      "       Cluster 89: 94\n",
      "       Cluster 90: 94\n",
      "       Cluster 91: 282\n",
      "       Cluster 92: 151\n",
      "       Cluster 93: 567\n",
      "       Cluster 94: 94\n",
      "       Cluster 95: 94\n",
      "       Cluster 96: 94\n",
      "       Cluster 97: 269\n",
      "       Cluster 98: 135\n",
      "       Cluster 99: 94\n",
      "       Cluster 100: 225\n",
      "       Cluster 101: 94\n",
      "       Cluster 102: 94\n",
      "       Cluster 103: 102\n",
      "       Cluster 104: 130\n",
      "       Cluster 105: 94\n",
      "       Cluster 106: 310\n",
      "       Cluster 107: 94\n",
      "       Cluster 108: 94\n",
      "       Cluster 109: 189\n",
      "       Cluster 110: 279\n",
      "       Cluster 111: 154\n",
      "       Cluster 112: 181\n",
      "       Cluster 113: 123\n",
      "       Cluster 114: 136\n",
      "       Cluster 115: 236\n",
      "       Cluster 116: 191\n",
      "       Cluster 117: 187\n",
      "       Cluster 118: 101\n",
      "       Cluster 119: 135\n",
      "       Cluster 120: 94\n",
      "       Cluster 121: 316\n",
      "       Cluster 122: 112\n",
      "       Cluster 123: 94\n",
      "       Cluster 124: 97\n",
      "       Cluster 125: 304\n",
      "       Cluster 126: 424\n",
      "       Cluster 127: 127\n",
      "       Cluster 128: 151\n",
      "       Cluster 129: 322\n",
      "       Cluster 130: 94\n",
      "       Cluster 131: 94\n",
      "       Cluster 132: 6835\n",
      "       Cluster 133: 94\n",
      "       Cluster 134: 94\n",
      "       Cluster 135: 144\n",
      "       Cluster 136: 94\n",
      "       Cluster 137: 1523\n",
      "       Cluster 138: 182\n",
      "       Cluster 139: 157\n",
      "       Cluster 140: 94\n",
      "       Cluster 141: 94\n",
      "       Cluster 142: 94\n",
      "       Cluster 143: 129\n",
      "       Cluster 144: 133\n",
      "       Cluster 145: 110\n",
      "       Cluster 146: 108\n",
      "       Cluster 147: 94\n",
      "       Cluster 148: 94\n",
      "       Cluster 149: 116\n",
      "       Cluster 150: 142\n",
      "       Cluster 151: 94\n",
      "       Cluster 152: 171\n",
      "       Cluster 153: 101\n",
      "       Cluster 154: 94\n",
      "       Cluster 155: 94\n",
      "       Cluster 156: 121\n",
      "       Cluster 157: 118\n",
      "       Cluster 158: 94\n",
      "       Cluster 159: 94\n",
      "       Cluster 160: 94\n",
      "       Cluster 161: 94\n",
      "       Cluster 162: 94\n",
      "       Cluster 163: 94\n",
      "       Cluster 164: 224\n",
      "       Cluster 165: 140\n",
      "       Cluster 166: 258\n",
      "       Cluster 167: 168\n",
      "       Cluster 168: 470\n",
      "       Cluster 169: 457\n",
      "       Cluster 170: 292\n",
      "       Cluster 171: 185\n",
      "       Cluster 172: 94\n",
      "       Cluster 173: 95\n",
      "       Cluster 174: 94\n",
      "       Cluster 175: 831\n",
      "       Cluster 176: 95\n",
      "       Cluster 177: 94\n",
      "       Cluster 178: 490\n",
      "       Cluster 179: 109\n",
      "       Cluster 180: 94\n",
      "       Cluster 181: 94\n",
      "       Cluster 182: 114\n",
      "       Cluster 183: 131\n",
      "       Cluster 184: 263\n",
      "       Cluster 185: 734\n",
      "       Cluster 186: 1302\n",
      "       Cluster 187: 96\n",
      "       Cluster 188: 150\n",
      "       Cluster 189: 94\n",
      "       Cluster 190: 287\n",
      "       Cluster 191: 144\n",
      "       Cluster 192: 104\n",
      "       Cluster 193: 94\n",
      "       Cluster 194: 94\n",
      "       Cluster 195: 121\n",
      "       Cluster 196: 94\n",
      "       Cluster 197: 504\n",
      "       Cluster 198: 447\n",
      "       Cluster 199: 175\n",
      "       Cluster 200: 94\n",
      "       Cluster 201: 94\n",
      "       Cluster 202: 170\n",
      "       Cluster 203: 94\n",
      "       Cluster 204: 94\n",
      "       Cluster 205: 94\n",
      "       Cluster 206: 94\n",
      "       Cluster 207: 125\n",
      "       Cluster 208: 94\n",
      "       Cluster 209: 94\n",
      "       Cluster 210: 94\n",
      "       Cluster 211: 166\n",
      "       Cluster 212: 94\n",
      "       Cluster 213: 193\n",
      "       Cluster 214: 94\n",
      "       Cluster 215: 94\n",
      "       Cluster 216: 94\n",
      "       Cluster 217: 94\n",
      "       Cluster 218: 111\n",
      "       Cluster 219: 94\n",
      "       Cluster 220: 152\n",
      "       Cluster 221: 832\n",
      "       Cluster 222: 144\n",
      "       Cluster 223: 127\n",
      "       Cluster 224: 94\n",
      "       Cluster 225: 209\n",
      "       Cluster 226: 159\n",
      "       Cluster 227: 94\n",
      "       Cluster 228: 94\n",
      "       Cluster 229: 94\n",
      "       Cluster 230: 94\n",
      "       Cluster 231: 126\n",
      "       Cluster 232: 110\n",
      "       Cluster 233: 353\n",
      "       Cluster 234: 342\n",
      "       Cluster 235: 282\n",
      "       Cluster 236: 116\n",
      "       Cluster 237: 170\n",
      "       Cluster 238: 94\n",
      "       Cluster 239: 3356\n",
      "       Cluster 240: 489\n",
      "       Cluster 241: 94\n",
      "       Cluster 242: 240\n",
      "       Cluster 243: 124\n",
      "       Cluster 244: 177\n",
      "       Cluster 245: 338\n",
      "       Cluster 246: 94\n",
      "       Cluster 247: 274\n",
      "       Cluster 248: 94\n",
      "       Cluster 249: 205\n",
      "       Cluster 250: 94\n",
      "       Cluster 251: 223\n",
      "       Cluster 252: 147\n",
      "       Cluster 253: 94\n",
      "       Cluster 254: 95\n",
      "       Cluster 255: 307\n",
      "       Cluster 256: 475\n",
      "       Cluster 257: 110\n",
      "       Cluster 258: 178\n",
      "       Cluster 259: 216\n",
      "       Cluster 260: 162\n",
      "       Cluster 261: 327\n",
      "       Cluster 262: 94\n",
      "       Cluster 263: 94\n",
      "       Cluster 264: 94\n",
      "       Cluster 265: 94\n",
      "       Cluster 266: 168\n",
      "       Cluster 267: 94\n",
      "       Cluster 268: 94\n",
      "       Cluster 269: 362\n",
      "       Cluster 270: 378\n",
      "       Cluster 271: 95\n",
      "       Cluster 272: 283\n",
      "       Cluster 273: 94\n",
      "       Cluster 274: 132\n",
      "       Cluster 275: 94\n",
      "       Cluster 276: 94\n",
      "       Cluster 277: 94\n",
      "       Cluster 278: 94\n",
      "       Cluster 279: 94\n",
      "       Cluster 280: 94\n",
      "       Cluster 281: 179\n",
      "       Cluster 282: 304\n",
      "       Cluster 283: 94\n",
      "       Cluster 284: 94\n",
      "       Cluster 285: 94\n",
      "       Cluster 286: 94\n",
      "       Cluster 287: 94\n",
      "       Cluster 288: 187\n",
      "       Cluster 289: 94\n",
      "       Cluster 290: 188\n",
      "       Cluster 291: 293\n",
      "       Cluster 292: 154\n",
      "       Cluster 293: 94\n",
      "       Cluster 294: 94\n",
      "       Cluster 295: 157\n",
      "       Cluster 296: 102\n",
      "       Cluster 297: 225\n",
      "       Cluster 298: 185\n",
      "       Cluster 299: 94\n",
      "       Cluster 300: 244\n",
      "       Cluster 301: 94\n",
      "       Cluster 302: 344\n",
      "       Cluster 303: 98\n",
      "       Cluster 304: 138\n",
      "       Cluster 305: 94\n",
      "       Cluster 306: 136\n",
      "       Cluster 307: 94\n",
      "       Cluster 308: 226\n",
      "       Cluster 309: 182\n",
      "       Cluster 310: 324\n",
      "       Cluster 311: 94\n",
      "       Cluster 312: 111\n",
      "       Cluster 313: 185\n",
      "       Cluster 314: 272\n",
      "       Cluster 315: 368\n",
      "       Cluster 316: 212\n",
      "       Cluster 317: 94\n",
      "       Cluster 318: 94\n",
      "       Cluster 319: 331\n",
      "       Cluster 320: 234\n",
      "       Cluster 321: 175\n",
      "       Cluster 322: 464\n",
      "       Cluster 323: 188\n",
      "       Cluster 324: 104\n",
      "       Cluster 325: 94\n",
      "       Cluster 326: 94\n",
      "       Cluster 327: 201\n",
      "       Cluster 328: 94\n",
      "       Cluster 329: 94\n",
      "       Cluster 330: 105\n",
      "       Cluster 331: 156\n",
      "       Cluster 332: 208\n",
      "       Cluster 333: 94\n",
      "       Cluster 334: 94\n",
      "       Cluster 335: 130\n",
      "       Cluster 336: 786\n",
      "       Cluster 337: 95\n",
      "       Cluster 338: 94\n",
      "       Cluster 339: 94\n",
      "       Cluster 340: 729\n",
      "       Cluster 341: 506\n",
      "       Cluster 342: 970\n",
      "       Cluster 343: 419\n",
      "       Cluster 344: 94\n",
      "       Cluster 345: 548\n",
      "       Cluster 346: 94\n",
      "       Cluster 347: 98\n",
      "       Cluster 348: 194\n",
      "       Cluster 349: 1060\n",
      "       Cluster 350: 94\n",
      "       Cluster 351: 322\n",
      "       Cluster 352: 138\n",
      "       Cluster 353: 94\n",
      "       Cluster 354: 155\n",
      "       Cluster 355: 2773\n",
      "       Cluster 356: 132\n",
      "  \n",
      "Predicting (scoring) new observation x:\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import timeit\n",
    "\n",
    "# If you use the source code or impliment pcStream, please cite the following paper:\n",
    "# Mirsky, Yisroel, Bracha Shapira, Lior Rokach, and Yuval Elovici. \"pcStream: A Stream Clustering Algorithm for Dynamically Detecting and Managing Temporal Contexts.\" In Advances in Knowledge Discovery and Data Mining (PAKDD), pp. 119-133. Springer International Publishing, 2015.\n",
    "\n",
    "#### Demo ####\n",
    "\n",
    "# generate a test dataset\n",
    "conceptDuration = 1000\n",
    "conceptDistributionScale = 1\n",
    "conceptOffset = 3\n",
    "numSequentialConcepts = 10\n",
    "n = 63 #number of features\n",
    "\n",
    "# DataGen = genDataset(conceptDuration,conceptDistributionScale,conceptOffset,numSequentialConcepts,n) #pcStream.genDataset is a python generator for testing purposes. It generates random sequential overalping normal distributions\n",
    "# Dataset = list()\n",
    "\n",
    "# for x in DataGen:\n",
    "#     Dataset.append(x)\n",
    "Dataset=x[:87500]\n",
    "m = len(Dataset) #length of stream\n",
    "\n",
    "# Run pcStream\n",
    "driftThreshold = 8.7 # note, it is generally reccoemnded to zscore the dataset before hand. In which case, the driftThreshold is typically slightly above 1\n",
    "maxDriftSize = int(n*1.5)\n",
    "percentVarience = 0.60\n",
    "modelMemory = 10000\n",
    "\n",
    "pcS_args = (driftThreshold,maxDriftSize,percentVarience,modelMemory) #pcStream argumetns are passed to the function as a tuple\n",
    "start = timeit.default_timer()\t\n",
    "Result =pcS(Dataset,pcS_args) #Result is the tuple (pcStreamModelCollection, clusterLabels)\n",
    "stop = timeit.default_timer()\n",
    "modelCollection  = Result[0]\n",
    "\n",
    "print \"============  Done.  ============\"\n",
    "print \"It took \" + str(stop-start) + \" seconds to train pcStream over a stream of \" + str(m) + \"  \" + str(n) + \"-dimensional observations.\"\n",
    "print \"   Number of clusters found: \" + str(len(modelCollection))\n",
    "print \"   The clusters have the following number of assigned observations:  \"\n",
    "for cluster in range(0,len(modelCollection)): #a pcStream cluster has the form (X,A,mu) -see the paper\n",
    "    print \"       Cluster \" + str(cluster) + \": \" + str(len(modelCollection[cluster][0]))\n",
    "\n",
    "print \"  \"\n",
    "print \"Predicting (scoring) new observation x:\"\n",
    "#x =genDataset(conceptDuration,conceptDistributionScale,conceptOffset,numSequentialConcepts,n).next() # some random observation...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/lr27/lib/python2.7/site-packages/ipykernel_launcher.py:12: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Counter({170: 5178, 11: 4053, 315: 957, 355: 798, 356: 724, 335: 191, 57: 148, 279: 118, 56: 99, 7: 58, 12: 34, 109: 26, 174: 25, 6: 18, 349: 17, 17: 7, 41: 5, 47: 4, 48: 4, 84: 4, 351: 4, 98: 4, 187: 4, 312: 2, 314: 2, 242: 2, 1: 1, 223: 1, 16: 1, 288: 1, 296: 1, 311: 1, 334: 1, 345: 1, 207: 1, 225: 1, 103: 1, 104: 1, 111: 1, 340: 1}), Counter({0.0: 7379, 1.0: 5121}))\n"
     ]
    }
   ],
   "source": [
    "y_pred=[]\n",
    "for i in x[87500:]:\n",
    "    y_pred.append(classifyOb(i, modelCollection))\n",
    "import collections\n",
    "count2=collections.Counter(y_pred )\n",
    "count3=collections.Counter(y[87500:] )\n",
    "print(count2,count3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2=[]\n",
    "for i in y_pred:\n",
    "    if i==170:\n",
    "        y_pred2.append(0)\n",
    "    else:\n",
    "        y_pred2.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 7322, 0: 5178})\n"
     ]
    }
   ],
   "source": [
    "count2=collections.Counter(y_pred2)\n",
    "print(count2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('AUC', 0.7410369161163644)\n",
      "('Precision', 0.6087134662660475)\n",
      "('Recall', 0.8703378246436243)\n",
      "('f1_score', 0.7163867234589729)\n",
      "[[4514 2865]\n",
      " [ 664 4457]]\n",
      "('TPR', 0.8703378246436243)\n",
      "('FPR', 0.38826399241089576)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "import sklearn as sk\n",
    "def evaluate(actual, predictions):\n",
    "    FPR, TPR, thresholds = roc_curve(actual, predictions)\n",
    "    cen = auc(FPR, TPR) \n",
    "    RightIndex=(TPR+(1-FPR)-1)\n",
    "    index=np.argmax(RightIndex)\n",
    "    tpr_val=TPR[index]\n",
    "    fpr_val=FPR[index]\n",
    "    thresholds_val=thresholds[index]\n",
    "    y_pred=[0 if i<thresholds_val else 1 for i in predictions]\n",
    "    y_pred_test=y_pred\n",
    "    y_test_test=actual\n",
    "    pre=sk.metrics.precision_score(y_test_test, y_pred_test)\n",
    "    rec=sk.metrics.recall_score(y_test_test, y_pred_test)\n",
    "    f1= sk.metrics.f1_score(y_test_test, y_pred_test)\n",
    "    print(\"AUC\", cen)\n",
    "    print(\"Precision\", pre)\n",
    "    print( \"Recall\",rec)\n",
    "    print( \"f1_score\", f1)\n",
    "    mat=sk.metrics.confusion_matrix(y_test_test, y_pred_test)\n",
    "    tp=mat[1][1]\n",
    "    fn=mat[1][0]\n",
    "    fp=mat[0][1]\n",
    "    tn=mat[0][0]\n",
    "    print(mat)\n",
    "    print(\"TPR\",tp*1.0/(tp+fn))\n",
    "    print(\"FPR\",fp*1.0/(tn+fp))\n",
    "evaluate(y[87500:],y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('AUC', 0.9010169377418287)\n",
      "('Precision', 0.9130164002491177)\n",
      "('Recall', 0.8588166373755126)\n",
      "('f1_score', 0.8850875427651439)\n",
      "[[6960  419]\n",
      " [ 723 4398]]\n",
      "('TPR', 0.8588166373755126)\n",
      "('FPR', 0.056782761891855264)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "import sklearn as sk\n",
    "def evaluate(actual, predictions):\n",
    "    FPR, TPR, thresholds = roc_curve(actual, predictions)\n",
    "    cen = auc(FPR, TPR) \n",
    "    RightIndex=(TPR+(1-FPR)-1)\n",
    "    index=np.argmax(RightIndex)\n",
    "    tpr_val=TPR[index]\n",
    "    fpr_val=FPR[index]\n",
    "    thresholds_val=thresholds[index]\n",
    "    y_pred=[0 if i<thresholds_val else 1 for i in predictions]\n",
    "    y_pred_test=y_pred\n",
    "    y_test_test=actual\n",
    "    pre=sk.metrics.precision_score(y_test_test, y_pred_test)\n",
    "    rec=sk.metrics.recall_score(y_test_test, y_pred_test)\n",
    "    f1= sk.metrics.f1_score(y_test_test, y_pred_test)\n",
    "    print(\"AUC\", cen)\n",
    "    print(\"Precision\", pre)\n",
    "    print( \"Recall\",rec)\n",
    "    print( \"f1_score\", f1)\n",
    "    mat=sk.metrics.confusion_matrix(y_test_test, y_pred_test)\n",
    "    tp=mat[1][1]\n",
    "    fn=mat[1][0]\n",
    "    fp=mat[0][1]\n",
    "    tn=mat[0][0]\n",
    "    print(mat)\n",
    "    print(\"TPR\",tp*1.0/(tp+fn))\n",
    "    print(\"FPR\",fp*1.0/(tn+fp))\n",
    "evaluate(y[87500:],y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:lr27]",
   "language": "python",
   "name": "conda-env-lr27-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
